---
title: "Week 4: Roots"
subtitle: "W4S2: Newton's and Secant methods"
format:
  live-revealjs:
    slide-number: true
    brand: ../_brand.yml
    theme: ../hevs.scss
    show-slide-number: all
    preview-links: auto
    chalkboard: true
    logo: https://www.hevs.ch/_nuxt/img/logo_hesso.9af1d79.svg
    footer: "W4S2 - Newton and Secant"
    include-in-header: ../_includes/revealscript.html
    include-after-body: ../_includes/backbutton.html
    
execute:
  echo: true       # ← this shows code
  output: true     # ← this shows output
  eval: true       # ← this runs the code
---

## Newton-Raphson Method (Root Finding)

![](img/NewtonIteration_Ani.gif)

> ::: callout-tip
**Highlight:** Newton = “solve the linear (tangent) approximation for the root.”
:::

---

### From Taylor series (first order)**
$$
f(x) \approx f(x_k) + f'(x_k)\,(x-x_k)
$$
Set the approximation to zero to get the next iterate:
$$
0 \approx f(x_k) + f'(x_k)\,(x_{k+1}-x_k)
\;\Rightarrow\; \\
\boxed{x_{k+1} = x_k - \dfrac{f(x_k)}{f'(x_k)}}
$$



## Newton-Raphson Method: Behavior & Practice

**Convergence**

- **Quadratic** near a simple root if $f'(x^{*})\neq 0$ and initial guess is close.
- Very fast when it works.

---

### Requirements

- Need $f'(x)$ (analytic or automatic differentiation).
- Good initial guess helps a lot.

---

### Pitfalls

- Can diverge or cycle if started poorly.
- Fails if $f'(x_k)=0$ (division by zero) or derivatives are noisy.
- May jump across discontinuities or non-smooth regions.

### Misc

- Hybridize with **bisection** when sign change is known.


## Secant Method (Gradient-Free Newton)

![](img/Metodo_delle_secanti.gif)

> ::: callout-note
**Highlight:** Secant ≈ “Newton without derivatives.”
:::

---

### Gradient free

**Motivation:** avoid computing $f'(x)$.

**Finite-difference surrogate for the derivative**
$$
f'(x_k) \approx \frac{f(x_k)-f(x_{k-1})}{x_k-x_{k-1}}
$$

---

### Plug into Newton’s update
$$
\boxed{
x_{k+1} = x_k - f(x_k)\,
\frac{x_k - x_{k-1}}{\,f(x_k) - f(x_{k-1})\,}
}
$$

---

## Usage

- Needs **two initial guesses** $x_0, x_1$.
- Each step uses the **secant slope** through $(x_{k-1},f_{k-1})$ and $(x_k,f_k)$.

## Lab

- [scipy.optimize.root()](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.root.html)

```python
# Usage example for system of non linear equation

import numpy as np
from scipy.optimize import root

# Define the nonlinear system
def F(vars):
    x, y = vars
    return [
        x**2 + y**2 - 4, 
        x * np.exp(y) - 1
    ]

# Initial guess
x0 = [1.0, 0.0]

# Solve using root
sol = root(F, x0, method='hybr') # whcih method to use

if sol.success:
    x_sol, y_sol = sol.x
    print(f"Converged: x = {x_sol:.6f}, y = {y_sol:.6f}")
else:
    print("Root finding did not converge!")

# Check residuals
print("Residuals:", F(sol.x))

```






